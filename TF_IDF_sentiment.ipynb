{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rudradeep22/Tweet_Decoder/blob/main/TF_IDF_sentiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2VR5yE2Q1lD"
      },
      "source": [
        "# Preprocessing\n",
        "\n",
        "In this Assignment, we will be exploring how to preprocess tweets for sentiment analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Try8QG5xQ1lL"
      },
      "outputs": [],
      "source": [
        "import nltk                                # Python library for NLP\n",
        "from nltk.corpus import twitter_samples    # sample Twitter dataset from NLTK\n",
        "import matplotlib.pyplot as plt            # library for visualization\n",
        "import random                              # pseudo-random number generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puelnnDoQ1lM"
      },
      "source": [
        "## About the Twitter dataset\n",
        "\n",
        "The sample dataset from NLTK is separated into positive and negative tweets. It contains 5000 positive tweets and 5000 negative tweets exactly. The exact match between these classes is not a coincidence. The intention is to have a balanced dataset. That does not reflect the real distributions of positive and negative classes in live Twitter streams.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxKktlhMQ1lN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "858d7274-aa2a-49a1-9e0b-e0bc49b335fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Package twitter_samples is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# downloads sample twitter dataset.\n",
        "nltk.download('twitter_samples')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjWs6tqbQ1lN"
      },
      "source": [
        "We can load the text fields of the positive and negative tweets by using the module's `strings()` method like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCN9YKaCQ1lN"
      },
      "outputs": [],
      "source": [
        "# select the set of positive and negative tweets\n",
        "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfK_KjdIQ1lO"
      },
      "source": [
        "Next, we'll print a report with the number of positive and negative tweets. It is also essential to know the data structure of the datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_XrygbufQ1lO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3b0be9f-3acf-4bc3-a2a9-87e26c266567"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of positive tweets:  5000\n",
            "Number of negative tweets:  5000\n",
            "\n",
            "The type of all_positive_tweets is:  <class 'list'>\n",
            "The type of a tweet entry is:  <class 'str'>\n",
            "hopeless for tmr :(\n"
          ]
        }
      ],
      "source": [
        "print('Number of positive tweets: ', len(all_positive_tweets))\n",
        "print('Number of negative tweets: ', len(all_negative_tweets))\n",
        "\n",
        "print('\\nThe type of all_positive_tweets is: ', type(all_positive_tweets))\n",
        "print('The type of a tweet entry is: ', type(all_negative_tweets[0]))\n",
        "print(all_negative_tweets[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9SEd0krQ1lP"
      },
      "source": [
        "## Looking at raw texts\n",
        "\n",
        "\n",
        "\n",
        "Below, you will print one random positive and one random negative tweet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_4GnNOMQ1lP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d151236-6d7a-418f-b9cf-75f9dc53e13d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sometimes it's all about choosing between your ego and your relationship. :)\n",
            "@Morteraaaaa tuesday daw :(\n"
          ]
        }
      ],
      "source": [
        "print(all_positive_tweets[random.randint(0,5000)])\n",
        "print(all_negative_tweets[random.randint(0,5000)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VlhrXoUrQ1lQ"
      },
      "source": [
        "## Preprocess raw text for Sentiment analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3lDAfnMQ1lQ"
      },
      "source": [
        "Data preprocessing is one of the critical steps in any machine learning project. It includes cleaning and formatting the data before feeding into a machine learning algorithm. For NLP, the preprocessing steps are comprised of the following tasks:\n",
        "\n",
        "* Tokenizing the string\n",
        "* Lowercasing\n",
        "* Removing stop words and punctuation\n",
        "* Stemming\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bm6bNsrzQ1lQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec80c427-7e72-4d5a-8d94-e1c447d8ffa8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My beautiful sunflowers on a sunny Friday morning off :) #sunflowers #favourites #happy #Friday offâ€¦ https://t.co/3tfYom0N1i\n"
          ]
        }
      ],
      "source": [
        "# Our selected sample. Complex enough to exemplify each step\n",
        "tweet = all_positive_tweets[2277]\n",
        "print(tweet)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YyZR0yYwQ1lQ"
      },
      "source": [
        "Let's import a few more libraries for this purpose."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcviT9auQ1lR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19987c64-d571-4b56-c444-43fd56781d3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# download the stopwords from NLTK\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aT8QHMY5Q1lR"
      },
      "outputs": [],
      "source": [
        "import re                                  # library for regular expression operations\n",
        "import string                              # for string operations\n",
        "\n",
        "from nltk.corpus import stopwords          # module for stop words that come with NLTK\n",
        "from nltk.stem import PorterStemmer        # module for stemming\n",
        "from nltk.tokenize import TweetTokenizer   # module for tokenizing strings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VG3ImX_IQ1lR"
      },
      "source": [
        "### Remove hyperlinks,  Twitter marks and styles\n",
        "\n",
        "Since we have a Twitter dataset, we'd like to remove some substrings commonly used on the platform like the hashtag, retweet marks, and hyperlinks. We'll use the [re](https://docs.python.org/3/library/re.html) library to perform regular expression operations on our tweet. We'll define our search pattern and use the `sub()` method to remove matches by substituting with an empty character (i.e. `''`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "a5IcXDqkQ1lR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "124007c9-6aec-409f-c2dd-f5d8952e3f24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My beautiful sunflowers on a sunny Friday morning off :) sunflowers favourites happy Friday offâ€¦ \n"
          ]
        }
      ],
      "source": [
        "# remove old style retweet text \"RT\"\n",
        "tweet2 = re.sub(r'^RT[\\s]+', '', tweet)\n",
        "\n",
        "# remove hyperlinks\n",
        "tweet2 = re.sub(r'https?://[^\\s\\n\\r]+', '', tweet2)\n",
        "\n",
        "# remove hashtags\n",
        "# only removing the hash # sign from the word\n",
        "tweet2 = re.sub(r'#', '', tweet2)\n",
        "\n",
        "print(tweet2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHn6jA0tQ1lR"
      },
      "source": [
        "### Tokenize the string\n",
        "\n",
        "To tokenize means to split the strings into individual words without blanks or tabs. In this same step, we will also convert each word in the string to lower case. The [tokenize](https://www.nltk.org/api/nltk.tokenize.html#module-nltk.tokenize.casual) module from NLTK allows us to do these easily:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzLGfUX3Q1lS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7bbdd19-281b-443a-84a8-01cb066d5f89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Tokenized string:\n",
            "['my', 'beautiful', 'sunflowers', 'on', 'a', 'sunny', 'friday', 'morning', 'off', ':)', 'sunflowers', 'favourites', 'happy', 'friday', 'off', 'â€¦']\n"
          ]
        }
      ],
      "source": [
        "# instantiate tokenizer class\n",
        "tokenizer = TweetTokenizer(preserve_case=False, strip_handles=True,\n",
        "                               reduce_len=True)\n",
        "\n",
        "# tokenize tweets\n",
        "tweet_tokens = tokenizer.tokenize(tweet2)\n",
        "\n",
        "print()\n",
        "print('Tokenized string:')\n",
        "print(tweet_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzhpto5LQ1lS"
      },
      "source": [
        "### Remove stop words and punctuations\n",
        "\n",
        "The next step is to remove stop words and punctuation. Stop words are words that don't add significant meaning to the text. You'll see the list provided by NLTK when you run the cells below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEuUul5rQ1lS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0db070b2-bb62-4d4e-8d64-501e43ddb67e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stop words\n",
            "\n",
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
            "\n",
            "Punctuation\n",
            "\n",
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
          ]
        }
      ],
      "source": [
        "#Import the english stop words list from NLTK\n",
        "stopwords_english = stopwords.words('english')\n",
        "\n",
        "print('Stop words\\n')\n",
        "print(stopwords_english)\n",
        "\n",
        "print('\\nPunctuation\\n')\n",
        "print(string.punctuation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgLmDiBNQ1lS"
      },
      "source": [
        "We can see that the stop words list above contains some words that could be important in some contexts.\n",
        "\n",
        "\n",
        "Time to clean up our tokenized tweet!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HNhIlrG1Q1lT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdb49383-412e-4abe-a5b1-22fb73afa41b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['my', 'beautiful', 'sunflowers', 'on', 'a', 'sunny', 'friday', 'morning', 'off', ':)', 'sunflowers', 'favourites', 'happy', 'friday', 'off', 'â€¦']\n",
            "removed stop words and punctuation:\n",
            "['beautiful', 'sunflowers', 'sunny', 'friday', 'morning', ':)', 'sunflowers', 'favourites', 'happy', 'friday', 'â€¦']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(tweet_tokens)\n",
        "\n",
        "tweets_clean = []\n",
        "\n",
        "for word in tweet_tokens: # Go through every word in your tokens list\n",
        "    if (word not in stopwords_english and  # remove stopwords\n",
        "        word not in string.punctuation):  # remove punctuation\n",
        "        tweets_clean.append(word)\n",
        "\n",
        "print('removed stop words and punctuation:')\n",
        "print(tweets_clean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lu-m6zZwQ1lT"
      },
      "source": [
        "Please note that the words **happy** and **sunny** in this list are correctly spelled."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYU0Fo6vQ1lT"
      },
      "source": [
        "### Stemming\n",
        "\n",
        "Stemming is the process of converting a word to its most general form, or stem. This helps in reducing the size of our vocabulary.\n",
        "\n",
        "Consider the words:\n",
        " * **learn**\n",
        " * **learn**ing\n",
        " * **learn**ed\n",
        " * **learn**t\n",
        "\n",
        "All these words are stemmed from its common root **learn**. However, in some cases, the stemming process produces words that are not correct spellings of the root word. For example, **happi** and **sunni**. That's because it chooses the most common stem for related words. For example, we can look at the set of words that comprises the different forms of happy:\n",
        "\n",
        " * **happ**y\n",
        " * **happi**ness\n",
        " * **happi**er\n",
        "\n",
        "We can see that the prefix **happi** is more commonly used. We cannot choose **happ** because it is the stem of unrelated words like **happen**.\n",
        "\n",
        "NLTK has different modules for stemming and we will be using the [PorterStemmer](https://www.nltk.org/api/nltk.stem.html#module-nltk.stem.porter) module which uses the [Porter Stemming Algorithm](https://tartarus.org/martin/PorterStemmer/). Let's see how we can use it in the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPUI2hi3Q1lT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "805490a0-15ff-47fe-9588-42b9cefa72e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['beautiful', 'sunflowers', 'sunny', 'friday', 'morning', ':)', 'sunflowers', 'favourites', 'happy', 'friday', 'â€¦']\n",
            "stemmed words:\n",
            "['beauti', 'sunflow', 'sunni', 'friday', 'morn', ':)', 'sunflow', 'favourit', 'happi', 'friday', 'â€¦']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(tweets_clean)\n",
        "\n",
        "# Instantiate stemming class\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# Create an empty list to store the stems\n",
        "tweets_stem = []\n",
        "\n",
        "for word in tweets_clean:\n",
        "    stem_word = stemmer.stem(word)  # stemming word\n",
        "    tweets_stem.append(stem_word)  # append to the list\n",
        "\n",
        "print('stemmed words:')\n",
        "print(tweets_stem)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_tweet=' '.join(tweets_stem)\n",
        "processed_tweet"
      ],
      "metadata": {
        "id": "-NlATHQ8z2Cc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "846681f8-6934-4070-caaf-e963175c49c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'beauti sunflow sunni friday morn :) sunflow favourit happi friday â€¦'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kXevPC2RQ1lU"
      },
      "source": [
        "That's it! Now we have a sentence which can be feed into to the next stage\n",
        "of our  project."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "."
      ],
      "metadata": {
        "id": "zBHp8KB83xz1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PART 2: Sentimental Analysis"
      ],
      "metadata": {
        "id": "wlUUC5S33jMQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "nltk.download('twitter_samples')\n",
        "# select the lists of positive and negative tweets\n",
        "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "all_negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
        "\n",
        "# concatenate the lists, 1st part is the positive tweets followed by the negative\n",
        "tweets = all_positive_tweets + all_negative_tweets"
      ],
      "metadata": {
        "id": "Ifa_z4zG3MH_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b6b353f-a7db-405e-c870-889d780db219"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Package twitter_samples is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print tweets here\n",
        "for i in range(5):\n",
        "  print(tweets[i])"
      ],
      "metadata": {
        "id": "P1qocwU-A_UO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29eb5c4b-da65-4835-dbbc-a99892acb694"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)\n",
            "@Lamb2ja Hey James! How odd :/ Please call our Contact Centre on 02392441234 and we will be able to assist you :) Many thanks!\n",
            "@DespiteOfficial we had a listen last night :) As You Bleed is an amazing track. When are you in Scotland?!\n",
            "@97sides CONGRATS :)\n",
            "yeaaaah yippppy!!!  my accnt verified rqst has succeed got a blue tick mark on my fb profile :) in 15 days\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y=np.zeros(10000)\n",
        "for i in range(5000):\n",
        "  y[i]=1"
      ],
      "metadata": {
        "id": "VRQ9PKcs6gAy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now make a function and implement pre-processing into all tweets and then make an array that contains all processed tweets as strings."
      ],
      "metadata": {
        "id": "u28Un7Yc2w0x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess(tweet_list):\n",
        "  tweet_preprocessed = []\n",
        "  for tweet in tweet_list:\n",
        "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
        "    tweet = re.sub(r'https?://[^\\s\\n\\r]+', '', tweet)\n",
        "    tweet = re.sub(r'#', '', tweet)\n",
        "    tweet_tokens = tokenizer.tokenize(tweet)\n",
        "    tweets_nostop = []\n",
        "    for word in tweet_tokens:\n",
        "        if (word not in stopwords_english and word not in string.punctuation):\n",
        "            tweets_nostop.append(word)\n",
        "    tweets_stem = []\n",
        "\n",
        "    for word in tweets_nostop:\n",
        "        stem_word = stemmer.stem(word)  # stemming word\n",
        "        tweets_stem.append(stem_word)\n",
        "    real_tweet = ' '.join(tweets_stem)\n",
        "    tweet_preprocessed.append(real_tweet)\n",
        "  return tweet_preprocessed\n",
        "\n",
        "tweet_input = preprocess(tweets)\n",
        "print(tweets[0])\n",
        "print(tweet_input[0])"
      ],
      "metadata": {
        "id": "HLvmNbV_3W1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9d41d05-891a-4841-8283-4ac77590cb5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#FollowFriday @France_Inte @PKuchly57 @Milipol_Paris for being top engaged members in my community this week :)\n",
            "followfriday top engag member commun week :)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now use **TfidfVectorizer** to vectorize your tweets into a numbered matrix\n",
        " **X**."
      ],
      "metadata": {
        "id": "zDYnvp9u4Rn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(tweet_input)\n",
        "vectorizer.get_feature_names_out()\n",
        "print(X.shape)\n",
        "print(X)\n"
      ],
      "metadata": {
        "id": "hG2SOoi83bTd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85e9916f-ac4e-42c4-b234-4b7b510428a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 9965)\n",
            "  (0, 9474)\t0.3163743685544463\n",
            "  (0, 2009)\t0.39684156715925367\n",
            "  (0, 5614)\t0.42367074190222104\n",
            "  (0, 2869)\t0.48691060414778675\n",
            "  (0, 8896)\t0.3905322374650137\n",
            "  (0, 3280)\t0.41632891686909285\n",
            "  (1, 8684)\t0.14398455939365618\n",
            "  (1, 5453)\t0.24472641259979364\n",
            "  (1, 851)\t0.3808202313249588\n",
            "  (1, 409)\t0.2698792465416714\n",
            "  (1, 11)\t0.3808202313249588\n",
            "  (1, 1717)\t0.344156230160084\n",
            "  (1, 2065)\t0.3001969049914373\n",
            "  (1, 1617)\t0.24031100037762068\n",
            "  (1, 6811)\t0.1766349082806141\n",
            "  (1, 6283)\t0.33686090615631203\n",
            "  (1, 4558)\t0.3091256599604902\n",
            "  (1, 4006)\t0.22349411793796045\n",
            "  (2, 7617)\t0.456153321645884\n",
            "  (2, 8930)\t0.4249801135191202\n",
            "  (2, 647)\t0.3177285261666004\n",
            "  (2, 1320)\t0.4679877180053548\n",
            "  (2, 6124)\t0.29174023114225733\n",
            "  (2, 5045)\t0.28760554843637565\n",
            "  (2, 5187)\t0.35145812803592463\n",
            "  :\t:\n",
            "  (9993, 8813)\t0.4871397406513321\n",
            "  (9994, 9373)\t0.6214503509755183\n",
            "  (9994, 4290)\t0.46487506956988567\n",
            "  (9994, 7009)\t0.5101354760950793\n",
            "  (9994, 8091)\t0.37074577137716075\n",
            "  (9995, 9206)\t0.6107897566592757\n",
            "  (9995, 909)\t0.5643262814812114\n",
            "  (9995, 9414)\t0.3624064802201592\n",
            "  (9995, 1753)\t0.42087202839358034\n",
            "  (9996, 3294)\t0.5796059823741202\n",
            "  (9996, 1491)\t0.5479074738373001\n",
            "  (9996, 7063)\t0.6032033697761969\n",
            "  (9997, 4549)\t0.61545926708577\n",
            "  (9997, 9532)\t0.5258111187364354\n",
            "  (9997, 6737)\t0.4403365132359038\n",
            "  (9997, 962)\t0.38837650943721075\n",
            "  (9998, 5510)\t0.5411067295925351\n",
            "  (9998, 549)\t0.5411067295925351\n",
            "  (9998, 5854)\t0.43047179839812316\n",
            "  (9998, 2091)\t0.47864500954593453\n",
            "  (9999, 5732)\t0.5423586745761582\n",
            "  (9999, 4191)\t0.5423586745761582\n",
            "  (9999, 3002)\t0.44025230127699744\n",
            "  (9999, 8429)\t0.35669066105688263\n",
            "  (9999, 9474)\t0.30107112076567216\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you have a matrix **X** and **y** implement a model to classify this tweets.\n",
        "\n",
        "Note:\n",
        "\n",
        "1) You can use sequential models with tensorflow in which use 2 nodes in last layer.\n",
        "\n",
        "2) The node which has a higher value while using *model.predict* corresponds to the output.\n",
        "\n",
        "3) Use **SparseCategoricalCrossentropy** as a loss function."
      ],
      "metadata": {
        "id": "WyO-tSZl7n4_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1234, shuffle=True)\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        layers.Dense(6000,input_shape=(X_train.shape[1],), activation='relu'),\n",
        "        layers.Dense(3000, activation='relu'),\n",
        "        layers.Dense(2, activation='softmax')\n",
        "    ]\n",
        ")\n",
        "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(), optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X_train.toarray(), y_train,validation_split=0.3, epochs = 50, batch_size=50)"
      ],
      "metadata": {
        "id": "iyha1mVG7fgh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a08fc2a-8fdf-4e17-a20a-d056da4e26ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "94/94 [==============================] - 4s 24ms/step - loss: 0.5595 - accuracy: 0.6977 - val_loss: 0.5166 - val_accuracy: 0.7289\n",
            "Epoch 2/50\n",
            "94/94 [==============================] - 2s 22ms/step - loss: 0.1808 - accuracy: 0.9333 - val_loss: 0.6844 - val_accuracy: 0.6950\n",
            "Epoch 3/50\n",
            "94/94 [==============================] - 2s 22ms/step - loss: 0.0754 - accuracy: 0.9701 - val_loss: 0.8416 - val_accuracy: 0.7114\n",
            "Epoch 4/50\n",
            "94/94 [==============================] - 2s 21ms/step - loss: 0.0431 - accuracy: 0.9804 - val_loss: 0.9100 - val_accuracy: 0.7035\n",
            "Epoch 5/50\n",
            "94/94 [==============================] - 2s 21ms/step - loss: 0.0336 - accuracy: 0.9819 - val_loss: 1.0226 - val_accuracy: 0.7134\n",
            "Epoch 6/50\n",
            "94/94 [==============================] - 2s 22ms/step - loss: 0.0282 - accuracy: 0.9849 - val_loss: 1.0998 - val_accuracy: 0.7020\n",
            "Epoch 7/50\n",
            "94/94 [==============================] - 2s 22ms/step - loss: 0.0282 - accuracy: 0.9836 - val_loss: 1.0272 - val_accuracy: 0.7085\n",
            "Epoch 8/50\n",
            "94/94 [==============================] - 2s 23ms/step - loss: 0.0261 - accuracy: 0.9840 - val_loss: 1.0765 - val_accuracy: 0.7154\n",
            "Epoch 9/50\n",
            "94/94 [==============================] - 2s 22ms/step - loss: 0.0261 - accuracy: 0.9857 - val_loss: 1.2875 - val_accuracy: 0.7109\n",
            "Epoch 10/50\n",
            "94/94 [==============================] - 2s 22ms/step - loss: 0.0284 - accuracy: 0.9846 - val_loss: 1.1894 - val_accuracy: 0.7080\n",
            "Epoch 11/50\n",
            "94/94 [==============================] - 2s 22ms/step - loss: 0.0267 - accuracy: 0.9849 - val_loss: 1.2074 - val_accuracy: 0.7139\n",
            "Epoch 12/50\n",
            "94/94 [==============================] - 2s 24ms/step - loss: 0.0266 - accuracy: 0.9829 - val_loss: 1.1569 - val_accuracy: 0.7124\n",
            "Epoch 13/50\n",
            "94/94 [==============================] - 2s 22ms/step - loss: 0.0264 - accuracy: 0.9857 - val_loss: 1.2373 - val_accuracy: 0.7035\n",
            "Epoch 14/50\n",
            "94/94 [==============================] - 2s 22ms/step - loss: 0.0250 - accuracy: 0.9851 - val_loss: 1.2350 - val_accuracy: 0.7134\n",
            "Epoch 15/50\n",
            "94/94 [==============================] - 2s 22ms/step - loss: 0.0257 - accuracy: 0.9859 - val_loss: 1.2288 - val_accuracy: 0.7000\n",
            "Epoch 16/50\n",
            "94/94 [==============================] - 2s 21ms/step - loss: 0.0263 - accuracy: 0.9855 - val_loss: 1.3590 - val_accuracy: 0.7085\n",
            "Epoch 17/50\n",
            "94/94 [==============================] - 2s 22ms/step - loss: 0.0272 - accuracy: 0.9842 - val_loss: 1.1231 - val_accuracy: 0.7025\n",
            "Epoch 18/50\n",
            "94/94 [==============================] - 2s 24ms/step - loss: 0.0252 - accuracy: 0.9851 - val_loss: 1.3421 - val_accuracy: 0.7060\n",
            "Epoch 19/50\n",
            "94/94 [==============================] - 2s 21ms/step - loss: 0.0260 - accuracy: 0.9842 - val_loss: 1.2479 - val_accuracy: 0.7100\n",
            "Epoch 20/50\n",
            "94/94 [==============================] - 2s 21ms/step - loss: 0.0224 - accuracy: 0.9859 - val_loss: 1.2400 - val_accuracy: 0.7060\n",
            "Epoch 21/50\n",
            "94/94 [==============================] - 2s 21ms/step - loss: 0.0216 - accuracy: 0.9868 - val_loss: 1.3985 - val_accuracy: 0.7025\n",
            "Epoch 22/50\n",
            "94/94 [==============================] - 2s 21ms/step - loss: 0.0212 - accuracy: 0.9876 - val_loss: 1.4617 - val_accuracy: 0.7109\n",
            "Epoch 23/50\n",
            "94/94 [==============================] - 2s 22ms/step - loss: 0.0212 - accuracy: 0.9876 - val_loss: 1.4893 - val_accuracy: 0.7095\n",
            "Epoch 24/50\n",
            "94/94 [==============================] - 2s 23ms/step - loss: 0.0211 - accuracy: 0.9876 - val_loss: 1.5477 - val_accuracy: 0.7025\n",
            "Epoch 25/50\n",
            "94/94 [==============================] - 2s 23ms/step - loss: 0.0210 - accuracy: 0.9868 - val_loss: 1.5742 - val_accuracy: 0.7080\n",
            "Epoch 26/50\n",
            "94/94 [==============================] - 2s 20ms/step - loss: 0.0213 - accuracy: 0.9876 - val_loss: 1.4979 - val_accuracy: 0.7070\n",
            "Epoch 27/50\n",
            "94/94 [==============================] - 2s 21ms/step - loss: 0.0209 - accuracy: 0.9876 - val_loss: 1.5888 - val_accuracy: 0.7075\n",
            "Epoch 28/50\n",
            "94/94 [==============================] - 2s 22ms/step - loss: 0.0215 - accuracy: 0.9878 - val_loss: 1.5096 - val_accuracy: 0.7075\n",
            "Epoch 29/50\n",
            "94/94 [==============================] - 2s 22ms/step - loss: 0.0210 - accuracy: 0.9870 - val_loss: 1.5504 - val_accuracy: 0.7065\n",
            "Epoch 30/50\n",
            "94/94 [==============================] - 2s 24ms/step - loss: 0.0209 - accuracy: 0.9868 - val_loss: 1.5805 - val_accuracy: 0.7124\n",
            "Epoch 31/50\n",
            "94/94 [==============================] - 2s 21ms/step - loss: 0.0210 - accuracy: 0.9870 - val_loss: 1.5719 - val_accuracy: 0.7055\n",
            "Epoch 32/50\n",
            "94/94 [==============================] - 2s 21ms/step - loss: 0.0209 - accuracy: 0.9878 - val_loss: 1.6059 - val_accuracy: 0.7075\n",
            "Epoch 33/50\n",
            "94/94 [==============================] - 2s 21ms/step - loss: 0.0221 - accuracy: 0.9874 - val_loss: 1.3774 - val_accuracy: 0.7020\n",
            "Epoch 34/50\n",
            "94/94 [==============================] - 2s 22ms/step - loss: 0.0211 - accuracy: 0.9876 - val_loss: 1.5071 - val_accuracy: 0.7095\n",
            "Epoch 35/50\n",
            "94/94 [==============================] - 2s 22ms/step - loss: 0.0211 - accuracy: 0.9866 - val_loss: 1.5180 - val_accuracy: 0.7104\n",
            "Epoch 36/50\n",
            "94/94 [==============================] - 2s 24ms/step - loss: 0.0208 - accuracy: 0.9878 - val_loss: 1.5807 - val_accuracy: 0.7104\n",
            "Epoch 37/50\n",
            "94/94 [==============================] - 2s 21ms/step - loss: 0.0207 - accuracy: 0.9878 - val_loss: 1.6481 - val_accuracy: 0.7100\n",
            "Epoch 38/50\n",
            "94/94 [==============================] - 2s 21ms/step - loss: 0.0208 - accuracy: 0.9878 - val_loss: 1.6847 - val_accuracy: 0.7134\n",
            "Epoch 39/50\n",
            "94/94 [==============================] - 2s 22ms/step - loss: 0.0206 - accuracy: 0.9878 - val_loss: 1.6438 - val_accuracy: 0.7124\n",
            "Epoch 40/50\n",
            "94/94 [==============================] - 2s 20ms/step - loss: 0.0206 - accuracy: 0.9876 - val_loss: 1.6448 - val_accuracy: 0.7109\n",
            "Epoch 41/50\n",
            "94/94 [==============================] - 2s 21ms/step - loss: 0.0208 - accuracy: 0.9876 - val_loss: 1.6505 - val_accuracy: 0.7104\n",
            "Epoch 42/50\n",
            "94/94 [==============================] - 2s 23ms/step - loss: 0.0210 - accuracy: 0.9872 - val_loss: 1.6386 - val_accuracy: 0.7114\n",
            "Epoch 43/50\n",
            "94/94 [==============================] - 2s 21ms/step - loss: 0.0207 - accuracy: 0.9876 - val_loss: 1.6141 - val_accuracy: 0.7095\n",
            "Epoch 44/50\n",
            "94/94 [==============================] - 2s 22ms/step - loss: 0.0206 - accuracy: 0.9878 - val_loss: 1.6918 - val_accuracy: 0.7104\n",
            "Epoch 45/50\n",
            "94/94 [==============================] - 2s 22ms/step - loss: 0.0204 - accuracy: 0.9870 - val_loss: 1.7001 - val_accuracy: 0.7070\n",
            "Epoch 46/50\n",
            "94/94 [==============================] - 2s 22ms/step - loss: 0.0206 - accuracy: 0.9878 - val_loss: 1.7316 - val_accuracy: 0.7095\n",
            "Epoch 47/50\n",
            "94/94 [==============================] - 2s 22ms/step - loss: 0.0205 - accuracy: 0.9876 - val_loss: 1.6868 - val_accuracy: 0.7075\n",
            "Epoch 48/50\n",
            "94/94 [==============================] - 2s 23ms/step - loss: 0.0207 - accuracy: 0.9868 - val_loss: 1.7447 - val_accuracy: 0.7070\n",
            "Epoch 49/50\n",
            "94/94 [==============================] - 2s 21ms/step - loss: 0.0204 - accuracy: 0.9874 - val_loss: 1.7657 - val_accuracy: 0.7080\n",
            "Epoch 50/50\n",
            "94/94 [==============================] - 2s 21ms/step - loss: 0.0245 - accuracy: 0.9872 - val_loss: 1.2565 - val_accuracy: 0.7085\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6a784f2e30>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(X_test.toarray())\n",
        "real_pred = []\n",
        "for i,j in predictions:\n",
        "  if i > j:\n",
        "    real_pred.append(0)\n",
        "  else:\n",
        "    real_pred.append(1)\n",
        "print(real_pred[:10])\n",
        "print(y_test[:10])\n",
        "sum =0\n",
        "for i in range(len(real_pred)):\n",
        "  if(real_pred[i] == y_test[i]):\n",
        "    sum += 1\n",
        "acc = sum/len(real_pred)\n",
        "print(f'Accuracy is :{acc}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3I8-zrjjmaY5",
        "outputId": "14895ce7-1e35-4779-a4fc-260b1584cbc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "104/104 [==============================] - 1s 8ms/step\n",
            "[1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "[1. 1. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
            "Accuracy is :0.723939393939394\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}